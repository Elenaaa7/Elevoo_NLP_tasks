{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "HkinrkVBwo5n"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers datasets rouge-score torch pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#I went from training two epochs on 170k steps to 500 steps aAnd still kaggle/colab crashes. 500 steps would get really bad results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FYfhDOQzwrNZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
        "import torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "from rouge_score import rouge_scorer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuRBPtH71Iq-",
        "outputId": "3d7eafcf-0753-4654-878a-7c10fe888a7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bad row at line 1: id,article,highlights\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/train.csv\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for i, line in enumerate(f, start=1):\n",
        "        try:\n",
        "            pd.read_csv(pd.compat.StringIO(line))\n",
        "        except Exception:\n",
        "            print(f\"Bad row at line {i}: {line}\")\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG0UvI4H0UqE",
        "outputId": "d739bc04-cc0c-4d9f-8d7a-30125426b121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                         id  \\\n",
            "0  0001d1afc246a7964130f43ae940af6bc6c57f01   \n",
            "1  0002095e55fcbd3a2f366d9bf92a95433dc305ef   \n",
            "2  00027e965c8264c35cc1bc55556db388da82b07f   \n",
            "3  0002c17436637c4fe1837c935c04de47adb18e9a   \n",
            "4  0003ad6ef0c37534f80b55b4235108024b407f0b   \n",
            "\n",
            "                                             article  \\\n",
            "0  By . Associated Press . PUBLISHED: . 14:11 EST...   \n",
            "1  (CNN) -- Ralph Mata was an internal affairs li...   \n",
            "2  A drunk driver who killed a young woman in a h...   \n",
            "3  (CNN) -- With a breezy sweep of his pen Presid...   \n",
            "4  Fleetwood are the only team still to have a 10...   \n",
            "\n",
            "                                          highlights  \n",
            "0  Bishop John Folda, of North Dakota, is taking ...  \n",
            "1  Criminal complaint: Cop used his role to help ...  \n",
            "2  Craig Eccleston-Todd, 27, had drunk at least t...  \n",
            "3  Nina dos Santos says Europe must be ready to a...  \n",
            "4  Fleetwood top of League One after 2-0 win at S...  \n",
            "Index(['id', 'article', 'highlights'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"/content/train.csv\", sep=\",\", quotechar='\"', on_bad_lines=\"skip\", engine=\"python\")\n",
        "val_df   = pd.read_csv(\"/content/validation.csv\", sep=\",\", quotechar='\"', on_bad_lines=\"skip\", engine=\"python\")\n",
        "test_df  = pd.read_csv(\"/content/test.csv\", sep=\",\", quotechar='\"', on_bad_lines=\"skip\", engine=\"python\")\n",
        "\n",
        "print(train_df.head())\n",
        "print(train_df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SP7HeWyB0gP8"
      },
      "outputs": [],
      "source": [
        "dataset = DatasetDict({\n",
        "    \"train\": Dataset.from_pandas(train_df),\n",
        "    \"validation\": Dataset.from_pandas(val_df),\n",
        "    \"test\": Dataset.from_pandas(test_df)\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pjtkwnhd1mTL"
      },
      "outputs": [],
      "source": [
        "model_name = \"facebook/bart-large-cnn\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "\n",
        "max_input_length = 512\n",
        "max_target_length = 128\n",
        "def preprocess_function(batch):\n",
        "    inputs = tokenizer(batch[\"article\"], max_length=max_input_length, truncation=True, padding=\"max_length\")\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(batch[\"highlights\"], max_length=max_target_length, truncation=True, padding=\"max_length\")\n",
        "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=[\"article\", \"highlights\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvUDESAK1rmO"
      },
      "outputs": [],
      "source": [
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2huwDhsk1twD"
      },
      "outputs": [],
      "source": [
        "def compute_rouge(eval_pred):\n",
        "    preds, labels = eval_pred\n",
        "    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": []}\n",
        "\n",
        "    for pred, ref in zip(decoded_preds, decoded_labels):\n",
        "        result = scorer.score(ref, pred)\n",
        "        for key in scores:\n",
        "            scores[key].append(result[key].fmeasure)\n",
        "\n",
        "    # Average over dataset\n",
        "    return {key: sum(vals)/len(vals) for key, vals in scores.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "8uWAwqhI1xNJ",
        "outputId": "1ba10fed-fb86-48d9-cec4-68cd7c3a79f4"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'TrainingArguments' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-161720483.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./results\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msave_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# adjust based on GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TrainingArguments' is not defined"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=2,   # adjust based on GPU\n",
        "    per_device_eval_batch_size=2,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    num_train_epochs=1,  # set higher for real training\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    report_to=[]\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "L0BT4hee1zAM",
        "outputId": "f586a65d-fd38-43a9-9d17-f0d5313a56bb"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Trainer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1202460668.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m trainer = Trainer(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Trainer' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_rouge,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "Qlx6_W5f11TR",
        "outputId": "501981c5-e986-4e01-870f-1b1263ae5c17"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-49973641.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ],
      "source": [
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wgKhNrP12_6"
      },
      "outputs": [],
      "source": [
        "results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
        "print(\"Test ROUGE Scores:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lieg-RRw14zy"
      },
      "outputs": [],
      "source": [
        "sample_text = test_df[\"article\"].iloc[0]\n",
        "inputs = tokenizer([sample_text], max_length=512, truncation=True, return_tensors=\"pt\")\n",
        "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, max_length=150, min_length=50)\n",
        "print(\"ARTICLE:\", sample_text[:500], \"...\")\n",
        "print(\"GENERATED SUMMARY:\", tokenizer.decode(summary_ids[0], skip_special_tokens=True))\n",
        "print(\"REFERENCE SUMMARY:\", test_df[\"highlights\"].iloc[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
